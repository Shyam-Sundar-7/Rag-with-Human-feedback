{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV file has been saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(folder_path):\n",
    "    # Get a list of all CSV files in the specified folder\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    # Initialize an empty DataFrame to store merged data\n",
    "    merged_df = pd.DataFrame(columns=[\"question\", \"context\", \"score\"])\n",
    "\n",
    "    # Iterate through each CSV file\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(folder_path, file))\n",
    "\n",
    "        # Extract required columns if they exist in the DataFrame\n",
    "        if \"question\" in df.columns and \"context\" in df.columns and \"score\" in df.columns:\n",
    "            # Append only the required columns to the merged DataFrame\n",
    "            merged_df = pd.concat([merged_df, df[[\"question\", \"context\", \"score\"]]], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Skipping {file} as it does not contain all required columns.\")\n",
    "\n",
    "    # Write the merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(\"merged_training_data.csv\", index=False)\n",
    "    print(\"Merged CSV file has been saved.\")\n",
    "\n",
    "# Specify the folder path where CSV files are located\n",
    "training_folder_path = \"training\"\n",
    "\n",
    "# Call the function to merge CSV files\n",
    "merge_csv_files(training_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from sentence-transformers) (4.40.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.10)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\desktop\\rag-with-human-feedback\\.venv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Desktop\\Rag-with-Human-feedback\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ASUS\\Desktop\\Rag-with-Human-feedback\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Desktop\\Rag-with-Human-feedback\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"merged_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is   Model Registry</td>\n",
       "      <td>models. We will now move on to the other criti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is   Model Registry</td>\n",
       "      <td>relevant elements of the context of your syste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is   Model Registry</td>\n",
       "      <td>model format abstraction and Model Registry  c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is   Model Registry</td>\n",
       "      <td>models: sklearn, XGBoost, TensorFlow, H20, fas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is   Model Registry</td>\n",
       "      <td>Introducing Model Registry     95\\r\\nIn the ML...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   question  \\\n",
       "0  what is   Model Registry   \n",
       "1  what is   Model Registry   \n",
       "2  what is   Model Registry   \n",
       "3  what is   Model Registry   \n",
       "4  what is   Model Registry   \n",
       "\n",
       "                                             context  score  \n",
       "0  models. We will now move on to the other criti...      0  \n",
       "1  relevant elements of the context of your syste...      0  \n",
       "2  model format abstraction and Model Registry  c...      0  \n",
       "3  models: sklearn, XGBoost, TensorFlow, H20, fas...      0  \n",
       "4  Introducing Model Registry     95\\r\\nIn the ML...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "train_samples=[]\n",
    "for _, row in df.iterrows():\n",
    "    train_samples.append(InputExample(texts=[row['question'], row['context']], label=row['score']))\n",
    "    train_samples.append(InputExample(texts=[row['context'], row['question']], label=row['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "# We add an evaluator, which evaluates the performance during training\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(train_samples, name=\"sts-dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# We create a DataLoader to load our train samples\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 3/3 [00:07<00:00,  2.48s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.23s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.23s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.07s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.22s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.21s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:07<00:00,  2.55s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.21s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:07<00:00,  2.42s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.32s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.24s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.27s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.03s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:05<00:00,  1.98s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.30s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.09s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.21s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.20s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.02s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.21s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:06<00:00,  2.21s/it]\n",
      "Iteration: 100%|██████████| 3/3 [00:05<00:00,  1.93s/it]\n",
      "Epoch: 100%|██████████| 25/25 [03:45<00:00,  9.02s/it]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "# logger.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=10000,\n",
    "    warmup_steps=warmup_steps,\n",
    "    # output_path=model_save_path,\n",
    "    # use_amp=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/cross-encoder-trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=4 if len(df)>4 else len(df)\n",
    "df=df[:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"\"\n",
    "for _, row in df.iterrows():\n",
    "    context+=row['context']+\"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1069"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
